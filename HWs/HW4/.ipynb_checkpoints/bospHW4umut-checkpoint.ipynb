{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW4: Regression!\n",
    "\n",
    "*Due Tuesday 7 November at 14:20 on Blackboard.*\n",
    "\n",
    "Please just hand in this completed .ipynb file.\n",
    "\n",
    "<font color=\"red\">**IMPORTANT: Please name your file with your name(s). (e.g., \"Mary_Isaac_HW3.ipynb\")** </font> \n",
    "\n",
    "You may hand this in in pairs.  If you do, only one member of each pair needs to hand it in, just make it clear who your partner is.\n",
    "\n",
    "## Overview\n",
    "\n",
    "Recall the two previous HWs: \n",
    "* In HW2, we looked at the effect of a job training program on employment (and concluded that an RCT was the way to go...)\n",
    "* In HW3, we looked at the effect of having children on whether or not a woman works, in the US and in Turkey.\n",
    "\n",
    "Previously, we did this just by comparing means, and we hoped that because there was something random going on (an explicit RCT in HW2; or the same-sex vs different-sex instrument in HW3), we were actually getting at a causal relationship.\n",
    "\n",
    "In this HW, you'll revisit HW2 and HW3 with our new tool, **regression**!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part A: Job training program\n",
    "\n",
    "This is the same data that we used in HW2 (go back to HW2 for more details about it).\n",
    "\n",
    "## Part A1: Load the data.\n",
    "\n",
    "Run the following cells to load the data.\n",
    "\n",
    "**New Python Trick!** In this HW, we'll introduce a few new packages, like Pandas and StatsModels.  If you installed Python/Jupyter notebooks using Anaconda, you should already have these packages.  If you installed using pip, you may or may not have them, but if you don't, you can get them with \"pip install pandas\" and \"pip install statsmodels\" on the command line.\n",
    "\n",
    "**Note:** Be careful about user-friendly packages (like the ones we'll be using) that do lots of things for you!  You really want to make sure you know what they are doing!  If this were a more programming-intensive course, we'd make you implement all of these things from scratch in Python -- if you want a good exercise and you have some background knowledge, try to do that! :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Great! Data is loaded\n"
     ]
    }
   ],
   "source": [
    "# Import all of our favorite packages...\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels.formula.api import ols\n",
    "from matplotlib import pyplot as plt\n",
    "import csv\n",
    "\n",
    "# same deal as in previous assignments: load the csv file\n",
    "datafile = open('jobtraining.csv', newline='')\n",
    "dataDict = csv.DictReader(datafile, delimiter=\",\")\n",
    "\n",
    "# Turn this into a pandas dataframe, and cast the values as numeric\n",
    "dataPd = pd.DataFrame(dataDict)\n",
    "for var in dataDict.fieldnames:\n",
    "    dataPd[var] = pd.to_numeric(dataPd[var], errors='coerce')\n",
    "\n",
    "\n",
    "print(\"Great! Data is loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>treat</th>\n",
       "      <th>control</th>\n",
       "      <th>nexp1</th>\n",
       "      <th>nexp2</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>Black</th>\n",
       "      <th>Hispanic</th>\n",
       "      <th>married</th>\n",
       "      <th>nodegree</th>\n",
       "      <th>earnings_1975</th>\n",
       "      <th>earnings_1978</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>12383.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4368.413</td>\n",
       "      <td>14051.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>10740.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3335</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23918.730</td>\n",
       "      <td>12532.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3336</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24490.840</td>\n",
       "      <td>27750.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3337</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>25470.470</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3338</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>26254.180</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3339</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29389.000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3340 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      treat  control  nexp1  nexp2  age  education  Black  Hispanic  married  \\\n",
       "0         0        1      0      0   23         10      1         0        0   \n",
       "1         0        1      0      0   26         12      0         0        0   \n",
       "2         0        1      0      0   22          9      1         0        0   \n",
       "3         0        1      0      0   34          9      1         0        0   \n",
       "4         0        1      0      0   18          9      1         0        0   \n",
       "...     ...      ...    ...    ...  ...        ...    ...       ...      ...   \n",
       "3335      0        0      0      1   46         12      0         0        0   \n",
       "3336      0        0      0      1   26         16      0         0        0   \n",
       "3337      0        0      0      1   48          8      0         0        1   \n",
       "3338      0        0      0      1   50         12      0         0        1   \n",
       "3339      0        0      0      1   41         13      0         0        0   \n",
       "\n",
       "      nodegree  earnings_1975  earnings_1978  \n",
       "0            1          0.000           0.00  \n",
       "1            0          0.000       12383.68  \n",
       "2            1          0.000           0.00  \n",
       "3            1       4368.413       14051.16  \n",
       "4            1          0.000       10740.08  \n",
       "...        ...            ...            ...  \n",
       "3335         0      23918.730       12532.26  \n",
       "3336         0      24490.840       27750.00  \n",
       "3337         1      25470.470           0.00  \n",
       "3338         0      26254.180           0.00  \n",
       "3339         0      29389.000           0.00  \n",
       "\n",
       "[3340 rows x 12 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can print out the data set to see a few rows and also the field names.\n",
    "dataPd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remember that here's what each of these variables mean:**\n",
    "* treat: 1 if the subject was in the treatment group of the RCT, 0 otherwise\n",
    "* control: 1 if the subject was in the control group of the RCT, 0 otherwise\n",
    "* nexp1: 1 if the subject was not part of the NSW program, but was included in the first \"non-experimental\" control group.  (And 0 otherwise).\n",
    "* nexp2: Same as nexp1 but for the second \"non-experimental\" control group.\n",
    "* age: subject's age in 1975\n",
    "* education: years of education (as of 1975)\n",
    "* Black: 1 if the subject is Black, 0 otherwise\n",
    "* Hispanic: 1 if the subject is Hispanic, 0 otherwise\n",
    "* married: 1 if the subject was married in 1975\n",
    "* nodegree: 1 if the subject did *not* receive a high school degree (as of 1975) \n",
    "* earnings_1975: earnings (in dollars) in 1975 (Adjusted for inflation to 1982 dollars)\n",
    "* earnings_1978: earnings (in dollars) in 1978 (Adjusted for inflation to 1982 dollars)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we'll want to split out the experimental sample.  Run the code below to do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>treat</th>\n",
       "      <th>control</th>\n",
       "      <th>nexp1</th>\n",
       "      <th>nexp2</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>Black</th>\n",
       "      <th>Hispanic</th>\n",
       "      <th>married</th>\n",
       "      <th>nodegree</th>\n",
       "      <th>earnings_1975</th>\n",
       "      <th>earnings_1978</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>12383.680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4368.413</td>\n",
       "      <td>14051.160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>10740.080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>8881.665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4023.211</td>\n",
       "      <td>7382.549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4078.152</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>25142.240</td>\n",
       "      <td>4181.942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10941.350</td>\n",
       "      <td>15952.600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>722 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     treat  control  nexp1  nexp2  age  education  Black  Hispanic  married  \\\n",
       "0        0        1      0      0   23         10      1         0        0   \n",
       "1        0        1      0      0   26         12      0         0        0   \n",
       "2        0        1      0      0   22          9      1         0        0   \n",
       "3        0        1      0      0   34          9      1         0        0   \n",
       "4        0        1      0      0   18          9      1         0        0   \n",
       "..     ...      ...    ...    ...  ...        ...    ...       ...      ...   \n",
       "717      1        0      0      0   20          9      1         0        0   \n",
       "718      1        0      0      0   31          4      1         0        0   \n",
       "719      1        0      0      0   24         10      1         0        1   \n",
       "720      1        0      0      0   33         11      1         0        1   \n",
       "721      1        0      0      0   33         12      1         0        1   \n",
       "\n",
       "     nodegree  earnings_1975  earnings_1978  \n",
       "0           1          0.000          0.000  \n",
       "1           0          0.000      12383.680  \n",
       "2           1          0.000          0.000  \n",
       "3           1       4368.413      14051.160  \n",
       "4           1          0.000      10740.080  \n",
       "..        ...            ...            ...  \n",
       "717         1          0.000       8881.665  \n",
       "718         1       4023.211       7382.549  \n",
       "719         1       4078.152          0.000  \n",
       "720         1      25142.240       4181.942  \n",
       "721         0      10941.350      15952.600  \n",
       "\n",
       "[722 rows x 12 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This picks out the rows where either \"treat\" or \"control\" is equal to 1.\n",
    "expSample = dataPd.loc[dataPd['treat'] + dataPd['control'] == 1]\n",
    "expSample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part A2: Our first regression!\n",
    "\n",
    "In this part, we'll run a regression for just the experimental sample.  We'll fit a simple linear model of the form: [1978_earnings] = a + b[treat].\n",
    "\n",
    "That is, we want to estimate the \"best\" values of a and b so that the above equation is as close to being satisfied as possible.\n",
    "\n",
    "Run the following code to do this.  Here are what the arguments to the ols function mean:\n",
    "* The first argument \"earnings_1978 ~ treat\" describes the model we are trying to fit.  It says that we want to explain the variable \"earnings_1978\" in terms of the variable \"treat.\"  We'll see later that if we want to explain some variable Y in terms of multiple other variables, we'd use a plus sign, like \"earnings_1978 ~ treat + age\".\n",
    "* The second argument, expSample, is our dataset\n",
    "* The third argument, missing=\"drop\", is optional, and tells Python what to do with data that have missing observations.  In this case, we're telling it to drop those data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intercept    5090.048302\n",
       "treat         886.303731\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ols(\"earnings_1978 ~ treat\", expSample, missing=\"drop\").fit()\n",
    "model.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, you should have gotten a value for \"Intercept\" and value for \"treat\".  The \"Intercept\" is the best estimate for \"a\" above; it's the y-intercept of the line.  The \"treat\" is the best estimate for \"b\" above; it's the coefficient on the \"treatment\" variable.\n",
    "\n",
    "You can get more information about the regression by running the following command.  It tells you thinks like \"R-squared\", \"standard errors\", and \"p-values\", which quantify how good a fit this linear model is.\n",
    "\n",
    "We're not going to go into the details of how these are computed and what they mean, but here are some rules of thumb:\n",
    "\n",
    "## Rules of Thumb for Deciding if Regression Results are \"Important.\"\n",
    "* **Look at the \"std err\" column for each coefficient.**  If a coefficient's standard error is small relative to its value, then the estimate is precise. If the standard error is large relative to its value, then the estimate is not precise.  \n",
    "* **Look at the \"p-value\" in the column labeled \"P > |t|\".**  This translates the standard error into a statement about how surprised you should be.  It tells you the probability of seeing a coefficient that is this large in magnitude by chance.  Loosely, if we were to generate random samples from the same population, then how often would we get a coefficient of this size just by chance.  If this is very small (a \"standard\" threshold is less than 0.05), then we think that the relationship captured by that coefficient is \"statistically significant,\" aka, that it's a real effect, and not one that just showed up by random chance.  If this p-value is large, then we probably shouldn't read too much into the relationship captured by this coefficient. Note that if you look at 20 coefficients then even if there is nothing going on you should expect to be surprised by 1 of them!\n",
    "* **Look at the \"R-squared\" that appears at the top.**  This number tells us the share of the variance that is \"explained\" by the regressors.  If it is very close to zero, this means that most of the variance is *not* explained by the regression model, so we don't think that these factors do a good job of predicting/explaining the outcome.  If it is very close to 1, this means that most of the variance *is* predicted/explained by the regression model, so we do think that these factors do a good job of predicting/explaining the outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:          earnings_1978   R-squared:                       0.005\n",
      "Model:                            OLS   Adj. R-squared:                  0.003\n",
      "Method:                 Least Squares   F-statistic:                     3.525\n",
      "Date:                Tue, 07 Nov 2023   Prob (F-statistic):             0.0609\n",
      "Time:                        00:33:14   Log-Likelihood:                -7333.1\n",
      "No. Observations:                 722   AIC:                         1.467e+04\n",
      "Df Residuals:                     720   BIC:                         1.468e+04\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept   5090.0483    302.783     16.811      0.000    4495.606    5684.491\n",
      "treat        886.3037    472.086      1.877      0.061     -40.526    1813.134\n",
      "==============================================================================\n",
      "Omnibus:                      384.449   Durbin-Watson:                   1.982\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             3767.287\n",
      "Skew:                           2.195   Prob(JB):                         0.00\n",
      "Kurtosis:                      13.294   Cond. No.                         2.46\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we learned in class, a regression of this form is just finding a line of best fit.  Let's plot that and see what it looks like!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = model.params[\"Intercept\"]\n",
    "b = model.params[\"treat\"]\n",
    "x = expSample[\"treat\"]\n",
    "y = expSample[\"earnings_1978\"]\n",
    "\n",
    "\n",
    "linearX = [x/10 for x in range(-1, 12)]\n",
    "linearY = [a + b*x for x in linearX]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(np.array(x),np.array(y))\n",
    "#plt.ylabel(\"Treatment\")\n",
    "#plt.xlabel(\"1978 Earnings\")\n",
    "plt.xlabel(\"Treatment\")\n",
    "plt.ylabel(\"1978 Earnings\")\n",
    "plt.plot(linearX, linearY,color=\"red\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">Interpretation time!</font>\n",
    "\n",
    "<font color=\"red\"> Explain how the regression we just did relates to the RCT that the data come from. How should we interpret a and b, both in words and also in terms of jargon/notation we've already learned *before* Class 5?\n",
    "    \n",
    "<font color=\"red\">**TODO:** Double-click the box below and enter your answer. </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANSWER:** THE CELL BELOW INCLUDES THE PROOF FOR MY REASONING  \n",
    "\n",
    "The regression enabled us to represent a portion of the RCT data (1978 earnings and treatment) as a linear model in the form of a + b\\*Xj, where Xj is 1 if the person underwent the treatment and 0 otherwise. The linear model was created by taking the average 1978 earnings at treat = 0 & treat = 1 and constructing a line passing through those two points. Unfortunately, the regression table above suggests that this regression model isn't a good mathematical representation of the RCT outcomes. It certanly lacks in precision and has an extremely low R-squared value, which indicates that the variance in the RCT data cannot be explained by the model. However, note that the p-value for a is zero. This is because the regression model used the average 1978 earning of the control group (which was situated on the y-axis) as its y-intercept. Since that data was situated on the y-axis and we only have 2 treatment values (0 and 1), the p-value for the y-intercept is 0 by default. All in all, I am not impressed with this linear model. \n",
    "\n",
    "Let us acknowledge that a is the y-intercept of the regression line and is equal to the average earning in 1978 among the control group (treat = 0). Refering to the outcome of the computation in the cell below, we can see that a is equal to the mean 1978 earning among the control group. Hence, a represents the average outcome among non-treated group. Since this is an RCT, the effects of selection on levels and selection on treatment are negligibly small. Therefore, we can state that, in 1978, the people in the treatment would be earning $a (just as the non-treated people) if they had not been treated. Thus, a is the expected level of 1978 earnings of all people in the RCT if no treatment was applied.  \n",
    "\n",
    "On the other hand, b can be interpreted as the slope of the regression line. However, since the horizontal distance between the two treat values (0 and 1) is 1.0, b is also equal to the difference in the average 1978 earnings of the treatment and control groups. The differences between the 1978 earning averages of the two groups, or b, can be interpreted as the observational comparison. Just by looking at the average 1978 earnings, we can say that, on average, in 1978, the people in the treatment were earning $b more than those in the control group. Moreover, since b is positive, we can say that the treatment had a positive effect on 1978 earnings.  \n",
    "\n",
    "Since we are conducting an RCT, we can assume the effect of selection on levels and the effect of selection on treatment to be zero. By the same logic, the effects of confounding variables will be distributed evenly between the treatment and control groups. Therefore, b is also equal to the ATE on 1978 earnings. (observational effect = ATE in this RCT)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a = 5090.048 and the average 1978 earning in control group = 5090.048\n",
      "The average 1978 earning in treatment group = 5976.352\n",
      "The difference between the average earnings of 2 groups is: 886.304\n",
      "b = 886.304\n"
     ]
    }
   ],
   "source": [
    "expSample_dict_list = []\n",
    "for index, row in expSample.iterrows():\n",
    "    expSample_dict_list.append(row.to_dict())        # I really like lists of dict!\n",
    "\n",
    "records = [row for row in expSample_dict_list]\n",
    "\n",
    "control_1978 = [float(x[\"earnings_1978\"]) for x in records if x.get(\"treat\") == 0]\n",
    "treat_1978 = [float(x[\"earnings_1978\"]) for x in records if x.get(\"treat\") == 1]\n",
    "\n",
    "\n",
    "print(\"a =\",round(a,3),\"and the average 1978 earning in control group =\", round(np.mean(control_1978),3))\n",
    "print(\"The average 1978 earning in treatment group =\", round(np.mean(treat_1978),3))\n",
    "print(\"The difference between the average earnings of 2 groups is:\",round(np.mean(treat_1978)-np.mean(control_1978),3) )\n",
    "print(\"b =\", round(b,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part A3: Adding more variables\n",
    "\n",
    "Now we can throw a few more variables into the model.  More precisely, let's fit a model of the form:\n",
    "\n",
    "[earnings_1978] = a + b[treat] + c[age] + d[education] + ... + z[earnings_1975]\n",
    "\n",
    "(that is, we'll throw in all of the variables!)\n",
    "\n",
    "Run the following cell to do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:          earnings_1978   R-squared:                       0.043\n",
      "Model:                            OLS   Adj. R-squared:                  0.032\n",
      "Method:                 Least Squares   F-statistic:                     3.966\n",
      "Date:                Tue, 07 Nov 2023   Prob (F-statistic):           0.000131\n",
      "Time:                        00:33:15   Log-Likelihood:                -7319.1\n",
      "No. Observations:                 722   AIC:                         1.466e+04\n",
      "Df Residuals:                     713   BIC:                         1.470e+04\n",
      "Df Model:                           8                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=================================================================================\n",
      "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------\n",
      "Intercept      3879.6043   2604.433      1.490      0.137   -1233.670    8992.878\n",
      "treat           806.5113    467.887      1.724      0.085    -112.090    1725.112\n",
      "age              17.3925     36.188      0.481      0.631     -53.654      88.439\n",
      "education       175.3231    179.581      0.976      0.329    -177.248     527.894\n",
      "Black         -1445.5411    801.451     -1.804      0.072   -3019.028     127.946\n",
      "Hispanic         98.4219   1046.107      0.094      0.925   -1955.397    2152.240\n",
      "married          71.8650    652.266      0.110      0.912   -1208.727    1352.457\n",
      "nodegree       -470.3969    742.928     -0.633      0.527   -1928.986     988.192\n",
      "earnings_1975     0.1705      0.047      3.651      0.000       0.079       0.262\n",
      "==============================================================================\n",
      "Omnibus:                      396.062   Durbin-Watson:                   1.923\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             4392.537\n",
      "Skew:                           2.234   Prob(JB):                         0.00\n",
      "Kurtosis:                      14.227   Cond. No.                     6.93e+04\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 6.93e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "model = ols(\"earnings_1978 ~ treat + age + education + Black + Hispanic + married + nodegree + earnings_1975\", expSample, missing=\"drop\").fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, you should get a number in the \"coef\" column for \"Intercept\" -- that's the \"a\" in our equation -- and similarly coefficients on each of the other variables in our linear model.  You'll also get a lot of other information.  It's okay to ignore this for now since we haven't talked about what it all means, but take a look at them in light of the \"rules of thumb\" mentioned above.\n",
    "\n",
    "## <font color=\"red\">Interpretation time!</font>\n",
    "\n",
    "<font color=\"red\"> How should we interpret these numbers?  In particular, answer the following questions. (A sentence or two each is fine).</font>\n",
    "\n",
    "   1. How would you interpret the number on \"treat\"?  Would you interpret this the same way or differently as the number in our first regression?  Why or why not?  (In particular, is this number close to or far from the number that we got in the first regression?  Does that make sense?)\n",
    "   2. How would you interpret the number on, say \"education,\" or \"Black\"?  Do you interpret those numbers the same way you interpret the number on \"treat\"?  Why or why not?\n",
    "    \n",
    "<font color=\"red\">**TODO:** Double-click the box below and enter your answer. </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANSWER**: This model aims to predict the 1978 earnings of the RCT people as the following linear combination of features: \n",
    "\n",
    "1978_earnings ≈ Intercept + treat\\*(1 if treatment, 0 if control) + age\\*(subject's age in 1975) + ... + earnings_1975\\*(  earnings in dollars in 1975)\n",
    "\n",
    "1\\) Unlike the previous regression model which aimed to estimate the 1978 earnings of a person based solely on their participation in the treatment, this linear regression model takes multiple factors (age, education, race, ...) into account, among which is also the person's participation in the treatment. By considering several variables that might have an effect on a person's earnings, this regression model offers a better estimation/prediction both for the 1978 earnings themselves.\n",
    "\n",
    "However, obsevrable variables that we include in the regression may act as confounding variables. In turn, this weakens our estimation of ATE. \n",
    "\n",
    "Please also note that taking variables that don't have a strong connection to 1978 earnings into account may result in overfitting and degrade the quality of the 1978 income estimation. While the R-squared value for this regression is much higher than that of the first regression, implying that the variance among a much larger portion of the RCT population was explained by this model, most of the coefficients have large standard error relative to their values. Additionally, some of the coefficients have large p-values. This might indicate that some of the variables shouldn't have been included in this linear regression. \n",
    "\n",
    "In an ideal scenario, the \"treat\" value can be interpreted as the observational comparison among the groups of people who have the exactly same age, education, Black, Hispanic, married, nodegree, and earnings_1975. However, since there are most likely no two people with the exact same attributes (age, edu, ...) within the RCT population, the value of \"treat\" was calculated via the best linear unbiased estimator. Depending on the quality of the regression, the \"treat\" value resulting from this best-fitting could be interpreted as the ATE of \"treat\" on 1978 earnings. \n",
    "\n",
    "In this case, the \"treat\" value is not equal to the ATE on 1978 earnings because regression compromised the accuracy of \"treat\" when trying to account for other variables (age, edu, ...). In other words, the presense of other variables skewed the \"treat\" coefficient by making the regression model consider their values when minimizing the total square sum error. The \"treat\" is a poor/non-ideal estimation of observational comparison and ATE. \n",
    "\n",
    "This interpretation is different than the one that I offered for \"treat\" in the first regression; there, the \"treat\" value represented the observational comparison and the ATE among the whole RCT population. With this model, the \"treat\" coefficient isn't equal to the ATE.  \n",
    "\n",
    "In our first regression model, the value of the \"treat\" coefficient was 886.3 ; however, in the second regression model, the value of the \"treat\" coefficient is 806.5. The 'effect of treatment' prediction of this this regression model is lower than that of the first one. Nevertheless, (as we will see in A5 and A6) the difference of 79.8 is small -- 79.8 constitutes approximately 9% of the initial \"treat\" coefficient (886.3). This difference makes sense: taking more variables alongside the participation in treatment into account (unnecessarily) broadens the scope of the regression and decrease the quality of the \"treat\" estimation. Therefore, this difference of 79.8 can be attributed to the possibility that the second linear model underestimated the average treatment effect by \\$79.8 due to the presence of observables in the calculation/error minization.\n",
    "\n",
    "2\\) Recall how performing an RCT enables us to evenly distribute every confounding variable to control and treatment groups. Being black or having education is not the primary determinant of the treatment effect: they are confounding variables.  Therefore, although the Black coefficient has large magnitude, much larger than that of \"treat\", it cannot be interpreted as the effect of being a black person on 1978 earnings. Same can be said for education and other coefficients. Hence, while \"treat\" coefficient can be either a good or a bad estimation of ATE on 1978 earnings, the other variables do not enable us to assess the effect of the treatment itself.  \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part A4: Using the non-experimental \"control\" group.\n",
    "\n",
    "Recall that in HW2, there was an experimental group that we looked at above, where we had a treatment and control group from an RCT.  There was also a non-experimental \"control\" group that researchers tried to construct from separate observational data.  Let's make a data set with the real (experimental) treatment group, and the non-experimental \"control\" group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "withNonExpControl = dataPd.loc[dataPd['treat'] + dataPd['nexp2'] == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's run a regression to fit a model of the form:\n",
    "\n",
    "[treat] = a + b*[age] + c*[education] + ...\n",
    "\n",
    "That is, we are thinking about selection into the *treatment* group as the output variable, and we are wondering what observables predict that.  Run the following cell to do that regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  treat   R-squared:                       0.463\n",
      "Model:                            OLS   Adj. R-squared:                  0.454\n",
      "Method:                 Least Squares   F-statistic:                     51.36\n",
      "Date:                Tue, 07 Nov 2023   Prob (F-statistic):           1.44e-52\n",
      "Time:                        00:33:15   Log-Likelihood:                -139.77\n",
      "No. Observations:                 425   AIC:                             295.5\n",
      "Df Residuals:                     417   BIC:                             328.0\n",
      "Df Model:                           7                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=================================================================================\n",
      "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------\n",
      "Intercept         0.7691      0.175      4.392      0.000       0.425       1.113\n",
      "age              -0.0151      0.002     -7.795      0.000      -0.019      -0.011\n",
      "education         0.0178      0.011      1.650      0.100      -0.003       0.039\n",
      "Black             0.2198      0.046      4.728      0.000       0.128       0.311\n",
      "Hispanic          0.1420      0.067      2.134      0.033       0.011       0.273\n",
      "married          -0.2479      0.042     -5.925      0.000      -0.330      -0.166\n",
      "nodegree          0.1710      0.050      3.389      0.001       0.072       0.270\n",
      "earnings_1975 -5.504e-06   2.96e-06     -1.859      0.064   -1.13e-05    3.17e-07\n",
      "==============================================================================\n",
      "Omnibus:                       40.567   Durbin-Watson:                   0.792\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               51.247\n",
      "Skew:                          -0.745   Prob(JB):                     7.45e-12\n",
      "Kurtosis:                       3.819   Cond. No.                     7.61e+04\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 7.61e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "model = ols(\"treat ~ age + education + Black + Hispanic + married + nodegree + earnings_1975\", withNonExpControl, missing=\"drop\").fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">Interpretation time!</font>\n",
    "\n",
    "<font color=\"red\"> How should we interpret these numbers?  In particular, answer the following questions.  (A sentence or two each is fine).</font>\n",
    "\n",
    "   1. Which variables seem like they might be important for determining who is in the treatment group? Why?\n",
    "   2. What does your answer to question 1 tell you about whether or not we need to worry about selection effects? \n",
    "   \n",
    "<font color=\"red\">**TODO:** Double-click the box below and enter your answer. </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANSWER**: \n",
    "\n",
    "1. TODO Recall how coefficients/variables with low P-values represent a \"statistically significant\" relationships. Looking at the regression table above, we can observe that the P-values of age, Black, married, and non-degree fall below our P-value threshold of 0.05 . Therefore, those four variables appear to be important for determining who is in the treatment group. \n",
    "2. TODO We certainly have to worry about the selection effects among when using this non-experimental control group. The aforamentioned four statistically important variables are associated with the increased likelihood of being included in the treatment group. Therefore, there is most likely strong selection bias (when picking out the treatment groups). \n",
    "\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part A5.  Repeating A2 with the non-experimental \"control\" group.\n",
    "\n",
    "Recall that in HW2, when we did the observational comparison with the non-experimental \"control\" group, we got something that was pretty different than the observational comparison with the experimental control group.  Let's do the same thing with regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:          earnings_1978   R-squared:                       0.053\n",
      "Model:                            OLS   Adj. R-squared:                  0.051\n",
      "Method:                 Least Squares   F-statistic:                     23.64\n",
      "Date:                Tue, 07 Nov 2023   Prob (F-statistic):           1.64e-06\n",
      "Time:                        01:02:29   Log-Likelihood:                -4336.4\n",
      "No. Observations:                 425   AIC:                             8677.\n",
      "Df Residuals:                     423   BIC:                             8685.\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept   2610.6959    578.718      4.511      0.000    1473.174    3748.217\n",
      "treat       3365.6561    692.283      4.862      0.000    2004.914    4726.398\n",
      "==============================================================================\n",
      "Omnibus:                      288.363   Durbin-Watson:                   1.823\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             3815.854\n",
      "Skew:                           2.750   Prob(JB):                         0.00\n",
      "Kurtosis:                      16.610   Cond. No.                         3.41\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "model = ols(\"earnings_1978 ~ treat\", withNonExpControl, missing=\"drop\").fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">Interpretation time!</font>\n",
    "\n",
    "<font color=\"red\"> How does the coefficient on \"treat\" compare to what you got in Part A2?  How do you interpret that difference?</font>\n",
    "\n",
    "   \n",
    "<font color=\"red\">**TODO:** Double-click the box below and enter your answer. </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANSWER:** The \"treat\" coefficient value is significantly greater than that in Part 2A. The \"treat\" value is equal to the ATE within this population. Based on the lower P-value of \"treat\", this regression model indicates that there is very strong correlation between treatment and earnings_1978, which is expected because researchers obtained the optimal match of observables. Therefore, this difference occurred due to the observable matching. \n",
    "\n",
    "Note that matching observables creates selection effects which might mislead us in terms of causality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part A6.  Can regression help us \"control\" for the selection effects?\n",
    "\n",
    "In part A4 you may have identified some possible confounding variables (e.g., that may be responsible for selection effects).  And in part A5 you may have seen that indeed there was a big discrepancy that these confounding variables may be responsible for.  (If you didn't see these things...maybe go back and double-check your work :) ).\n",
    "\n",
    "To that end, we might try to use regression to *control* for those variables that we think might be confounders.\n",
    "\n",
    "Write code below to run a regression with earnings_1978 as the dependent variable, \"treat\" as one of the independent variables, on the withNonExpControl dataset, **and** where you control on some variables that you are worried about.  Do you get an effect that's closer to what you got from the RCT?  (e.g., the effect from parts A2 and A3?)\n",
    "\n",
    "**Hint:** Use the previous examples of code as a template."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\"> Coding time! </font>\n",
    "\n",
    "<font color=\"red\"> Write code to do this below. Two lines should be enough. </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:          earnings_1978   R-squared:                       0.070\n",
      "Model:                            OLS   Adj. R-squared:                  0.059\n",
      "Method:                 Least Squares   F-statistic:                     6.329\n",
      "Date:                Tue, 07 Nov 2023   Prob (F-statistic):           1.11e-05\n",
      "Time:                        01:10:35   Log-Likelihood:                -4332.5\n",
      "No. Observations:                 425   AIC:                             8677.\n",
      "Df Residuals:                     419   BIC:                             8701.\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept   3450.7399   1522.939      2.266      0.024     457.186    6444.293\n",
      "treat       4338.0823    929.691      4.666      0.000    2510.644    6165.521\n",
      "age          -10.6429     37.263     -0.286      0.775     -83.889      62.603\n",
      "Black       -869.1995    743.383     -1.169      0.243   -2330.424     592.025\n",
      "married      958.7129    828.782      1.157      0.248    -670.376    2587.802\n",
      "nodegree   -1389.5296    698.228     -1.990      0.047   -2761.997     -17.062\n",
      "==============================================================================\n",
      "Omnibus:                      291.768   Durbin-Watson:                   1.787\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             4176.141\n",
      "Skew:                           2.762   Prob(JB):                         0.00\n",
      "Kurtosis:                      17.329   Cond. No.                         163.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "model = ols(\"earnings_1978 ~ treat + age + Black + married + nodegree\", withNonExpControl, missing=\"drop\").fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">Interpretation time!</font>\n",
    "\n",
    "<font color=\"red\"> What did you get? Do you think that using regression to help \"control\" for possible confounders can fix the issue and help you establish causality in the absence of an RCT?</font>\n",
    "\n",
    "\n",
    "<font color=\"red\">**TODO:** Double-click the box below and enter your answer. </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANSWER:**\n",
    "The P-values of the variables age, Black, and married are much greater in A6 than in A2. This indicates that the statistical significance of those confounding variables was dimished by us controlling for them. Nodegree is an exception -- it has a lower P-value in A6 than in A2. However, it is still well above the standard P-value threshold.  \n",
    "\n",
    "Moreover, the \"treat\" coefficient, or the treatment effect on earnings, is greater in A6 than it is in A5. In particular, controlling for the four variables resulted in the \"treat\" coefficient becomming even larger than it previously was (A5). The difference in the treatment effects of A5 and A6 is approximately 973 -- which is MUCH larger than the \"treat\" difference between A2 and A3. \n",
    "\n",
    "This strong discrepancy implies that regression was not really able to completely 'fix the issue' and 'establish causality' in the absence of the RCT. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part B: The effect of children on women's labor force participation\n",
    "\n",
    "Next, we'll move on to our example from HW3.\n",
    "\n",
    "**Recall** that the idea here is that someone is in the \"treatment\" group if their first two children had the same sex, because that means that they are (hopefully randomly...) slightly more likely to have a third child.  Othewise they are in the \"control\" group.\n",
    "\n",
    "Run the cell below to load the data.\n",
    "\n",
    "**NOTE:** This data set is slightly different than the one from HW3: we removed all of the women with <2 children, so that the code runs a bit faster.  It shouldn't affect anything (unless you did some extra credit), since the main assignment never looked at those women.\n",
    "\n",
    "## Part B1: Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please wait...\n",
      "Great! Data is loaded!\n"
     ]
    }
   ],
   "source": [
    "# same deal as in previous assignments: load the csv file\n",
    "datafile = open('childrenwork_reduced.csv', newline='')\n",
    "dataDict = csv.DictReader(datafile, delimiter=\",\")\n",
    "\n",
    "# Turn this into a pandas dataframe\n",
    "print(\"Please wait...\")\n",
    "dataPd = pd.DataFrame(dataDict)\n",
    "\n",
    "print(\"Great! Data is loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall from HW3 that here is what the variables mean. (Everything is calculated at the time of the survey, which was in the year 2000.)\n",
    "\n",
    "**Here are the most important ones for our purposes:**\n",
    "\n",
    "* country: either \"Turkey\" or \"USA\"\n",
    "* empstat: mother is currently employed (aka, 1 if she is employed, 0 otherwise)\n",
    "* three_or_more: equals 1 if there are three or more children, 0 otherwise\n",
    "* same_sex: equals 1 if first and second child have the same gender, 0 if different gender, and blank if <2 children.\n",
    "* nchild: number of children at the time of the survey\n",
    "\n",
    "**NOTE:** If a women doesn't have two or more children, then the \"same_sex\" variable will be blank.  (We will set it to the Python primitive None below).\n",
    "\n",
    "**And here are a bunch of other variables that might be interesting to look at!**\n",
    "\n",
    "* age: age of the mother\n",
    "* age1-age6: age of the 1st through 6th child in the data\n",
    "* education: mother’s years of education at the time of the survey\n",
    "* low_educ: an indicator for whether the mother has “low” education (the bottom 70% of education in Turkey, and the bottom 73% in the U.S.; in Turkey this is 5 years or less, in the U.S. this is 13 years or less)\n",
    "* married: mother is married\n",
    "* marr_divorce: mother is divorced\n",
    "* marr_separate: mother is separated\n",
    "* marr_single: mother is single\n",
    "* marr_widow:  mother is a widow\n",
    "* sex1-sex6: sex of the first 6 children  (In the original data, \"1\"=male; \"2\"=female; below we'll change that to \"F\" and \"M\" so we don't forget)\n",
    "* spouse_age: age of spouse\n",
    "* spouse_education: spouse years of education\n",
    "* spouse_empstat: spouse is employed (1=employed; 0= not employed)\n",
    "* two_boys: first two children are boys\n",
    "* two_girls: first two children are girls \n",
    "* two_or_more: equals 1 if there are two or more children, 0 otherwise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some data-wrangling\n",
    "\n",
    "Run the following two cells to cast the things that should be numeric to be numeric, and then to split this dataset into US and Turkey datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "should_be_numeric = [\"age\", \"age1\", \"age2\", \"age3\", \"age4\", \"age5\", \"age6\", \"empstat\", \"low_educ\", \"married\", \"marr_divorce\", \"marr_separate\", \"marr_single\", \"marr_widow\", \"nchild\", \"same_sex\", \"spouse_age\", \"spouse_empstat\", \"three_or_more\", \"two_boys\", \"two_girls\", \"two_or_more\", \"education\", \"spouse_education\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please wait...\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "print(\"Please wait...\")\n",
    "for var in should_be_numeric:\n",
    "        dataPd[var] = pd.to_numeric(dataPd[var], errors='coerce')\n",
    "\n",
    "dataUS = dataPd.loc[dataPd[\"country\"]==\"USA\"]\n",
    "dataTurkey = dataPd.loc[dataPd[\"country\"]==\"Turkey\"]\n",
    "print(\"done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex1</th>\n",
       "      <th>age1</th>\n",
       "      <th>sex2</th>\n",
       "      <th>age2</th>\n",
       "      <th>sex3</th>\n",
       "      <th>age3</th>\n",
       "      <th>sex4</th>\n",
       "      <th>age4</th>\n",
       "      <th>sex5</th>\n",
       "      <th>age5</th>\n",
       "      <th>...</th>\n",
       "      <th>marr_separate</th>\n",
       "      <th>marr_single</th>\n",
       "      <th>marr_widow</th>\n",
       "      <th>same_sex</th>\n",
       "      <th>two_boys</th>\n",
       "      <th>two_girls</th>\n",
       "      <th>country</th>\n",
       "      <th>two_or_more</th>\n",
       "      <th>three_or_more</th>\n",
       "      <th>low_educ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>194411</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>USA</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194412</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>USA</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194413</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>USA</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194414</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>USA</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194415</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>USA</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672873</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>USA</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672874</th>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>USA</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672875</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>USA</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672876</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>USA</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672877</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2</td>\n",
       "      <td>8.0</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>USA</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>478467 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sex1  age1 sex2  age2 sex3  age3 sex4  age4 sex5  age5  ...  \\\n",
       "194411    1     6    2     3    1   2.0        NaN        NaN  ...   \n",
       "194412    2     7    1     6        NaN        NaN        NaN  ...   \n",
       "194413    2     7    1     6        NaN        NaN        NaN  ...   \n",
       "194414    1     6    2     3    1   1.0        NaN        NaN  ...   \n",
       "194415    2     7    1     5    2   1.0        NaN        NaN  ...   \n",
       "...     ...   ...  ...   ...  ...   ...  ...   ...  ...   ...  ...   \n",
       "672873    2     7    2     5        NaN        NaN        NaN  ...   \n",
       "672874    1    13    1     9        NaN        NaN        NaN  ...   \n",
       "672875    1    12    1     6        NaN        NaN        NaN  ...   \n",
       "672876    2     8    2     7        NaN        NaN        NaN  ...   \n",
       "672877    1    15    1    13    1  11.0    2   8.0        NaN  ...   \n",
       "\n",
       "       marr_separate  marr_single  marr_widow  same_sex  two_boys  two_girls  \\\n",
       "194411           0.0          0.0         0.0         0         0          0   \n",
       "194412           0.0          0.0         0.0         0         0          0   \n",
       "194413           0.0          0.0         0.0         0         0          0   \n",
       "194414           0.0          0.0         0.0         0         0          0   \n",
       "194415           0.0          0.0         0.0         0         0          0   \n",
       "...              ...          ...         ...       ...       ...        ...   \n",
       "672873           0.0          0.0         0.0         1         0          1   \n",
       "672874           0.0          0.0         0.0         1         1          0   \n",
       "672875           0.0          0.0         0.0         1         1          0   \n",
       "672876           0.0          0.0         0.0         1         0          1   \n",
       "672877           0.0          0.0         0.0         1         1          0   \n",
       "\n",
       "        country  two_or_more  three_or_more  low_educ  \n",
       "194411      USA            1              1         0  \n",
       "194412      USA            1              0         0  \n",
       "194413      USA            1              0         0  \n",
       "194414      USA            1              1         0  \n",
       "194415      USA            1              1         0  \n",
       "...         ...          ...            ...       ...  \n",
       "672873      USA            1              0         1  \n",
       "672874      USA            1              0         1  \n",
       "672875      USA            1              0         1  \n",
       "672876      USA            1              0         1  \n",
       "672877      USA            1              1         1  \n",
       "\n",
       "[478467 rows x 31 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a quick look at the US data:\n",
    "dataUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex1</th>\n",
       "      <th>age1</th>\n",
       "      <th>sex2</th>\n",
       "      <th>age2</th>\n",
       "      <th>sex3</th>\n",
       "      <th>age3</th>\n",
       "      <th>sex4</th>\n",
       "      <th>age4</th>\n",
       "      <th>sex5</th>\n",
       "      <th>age5</th>\n",
       "      <th>...</th>\n",
       "      <th>marr_separate</th>\n",
       "      <th>marr_single</th>\n",
       "      <th>marr_widow</th>\n",
       "      <th>same_sex</th>\n",
       "      <th>two_boys</th>\n",
       "      <th>two_girls</th>\n",
       "      <th>country</th>\n",
       "      <th>two_or_more</th>\n",
       "      <th>three_or_more</th>\n",
       "      <th>low_educ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194406</th>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194407</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194408</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194409</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194410</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>194411 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sex1  age1 sex2  age2 sex3  age3 sex4  age4 sex5  age5  ...  \\\n",
       "0         1    15    2    13    1  11.0    2  10.0    1   9.0  ...   \n",
       "1         2     9    1     7    2   4.0    1   0.0        NaN  ...   \n",
       "2         1     2    2     0        NaN        NaN        NaN  ...   \n",
       "3         1    15    2    10    1   3.0        NaN        NaN  ...   \n",
       "4         2    13    1    11    1   8.0    1   0.0        NaN  ...   \n",
       "...     ...   ...  ...   ...  ...   ...  ...   ...  ...   ...  ...   \n",
       "194406    2    13    2    10    1   1.0        NaN        NaN  ...   \n",
       "194407    1    10    1     8    1   5.0        NaN        NaN  ...   \n",
       "194408    1    11    1     7        NaN        NaN        NaN  ...   \n",
       "194409    1    10    1     6        NaN        NaN        NaN  ...   \n",
       "194410    2     7    2     5    1   3.0        NaN        NaN  ...   \n",
       "\n",
       "       marr_separate  marr_single  marr_widow  same_sex  two_boys  two_girls  \\\n",
       "0                NaN          0.0         0.0         0         0          0   \n",
       "1                NaN          0.0         0.0         0         0          0   \n",
       "2                NaN          0.0         0.0         0         0          0   \n",
       "3                NaN          0.0         0.0         0         0          0   \n",
       "4                NaN          0.0         0.0         0         0          0   \n",
       "...              ...          ...         ...       ...       ...        ...   \n",
       "194406           NaN          0.0         0.0         1         0          1   \n",
       "194407           NaN          0.0         0.0         1         1          0   \n",
       "194408           NaN          0.0         0.0         1         1          0   \n",
       "194409           NaN          0.0         0.0         1         1          0   \n",
       "194410           NaN          0.0         0.0         1         0          1   \n",
       "\n",
       "        country  two_or_more  three_or_more  low_educ  \n",
       "0        Turkey            1              1         0  \n",
       "1        Turkey            1              1         0  \n",
       "2        Turkey            1              0         0  \n",
       "3        Turkey            1              1         0  \n",
       "4        Turkey            1              1         0  \n",
       "...         ...          ...            ...       ...  \n",
       "194406   Turkey            1              1         1  \n",
       "194407   Turkey            1              1         1  \n",
       "194408   Turkey            1              0         1  \n",
       "194409   Turkey            1              0         1  \n",
       "194410   Turkey            1              1         1  \n",
       "\n",
       "[194411 rows x 31 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And a quick look at the Turkish data:\n",
    "dataTurkey"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B2:  A few regressions...\n",
    "\n",
    "First, we're going to run **two** regressions (actually four, two in each of the US and Turkey).  We're not going to tell you what they mean, that will be your job..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:          three_or_more   R-squared:                       0.002\n",
      "Model:                            OLS   Adj. R-squared:                  0.002\n",
      "Method:                 Least Squares   F-statistic:                     1132.\n",
      "Date:                Tue, 07 Nov 2023   Prob (F-statistic):          8.68e-248\n",
      "Time:                        01:39:12   Log-Likelihood:            -3.3161e+05\n",
      "No. Observations:              478467   AIC:                         6.632e+05\n",
      "Df Residuals:                  478465   BIC:                         6.632e+05\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      0.3525      0.001    354.269      0.000       0.351       0.355\n",
      "same_sex       0.0471      0.001     33.639      0.000       0.044       0.050\n",
      "==============================================================================\n",
      "Omnibus:                  2006762.448   Durbin-Watson:                   1.978\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            80381.364\n",
      "Skew:                           0.509   Prob(JB):                         0.00\n",
      "Kurtosis:                       1.269   Cond. No.                         2.63\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "===========\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:          three_or_more   R-squared:                       0.005\n",
      "Model:                            OLS   Adj. R-squared:                  0.005\n",
      "Method:                 Least Squares   F-statistic:                     891.8\n",
      "Date:                Tue, 07 Nov 2023   Prob (F-statistic):          1.64e-195\n",
      "Time:                        01:39:12   Log-Likelihood:            -1.3919e+05\n",
      "No. Observations:              194411   AIC:                         2.784e+05\n",
      "Df Residuals:                  194409   BIC:                         2.784e+05\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      0.4051      0.002    254.081      0.000       0.402       0.408\n",
      "same_sex       0.0671      0.002     29.863      0.000       0.063       0.071\n",
      "==============================================================================\n",
      "Omnibus:                   696057.358   Durbin-Watson:                   1.985\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            31848.400\n",
      "Skew:                           0.245   Prob(JB):                         0.00\n",
      "Kurtosis:                       1.079   Cond. No.                         2.63\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Regression 1:\n",
    "\n",
    "modelUS = ols(\"three_or_more ~ same_sex\", dataUS,missing=\"drop\").fit()\n",
    "print(modelUS.summary())\n",
    "thing1_US = modelUS.params[\"same_sex\"]\n",
    "\n",
    "print(\"===========\")\n",
    "\n",
    "modelTk = ols(\"three_or_more ~ same_sex\", dataTurkey,missing=\"drop\").fit()\n",
    "print(modelTk.summary())\n",
    "thing1_Tk = modelTk.params[\"same_sex\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                empstat   R-squared:                       0.000\n",
      "Model:                            OLS   Adj. R-squared:                  0.000\n",
      "Method:                 Least Squares   F-statistic:                     5.621\n",
      "Date:                Tue, 07 Nov 2023   Prob (F-statistic):             0.0177\n",
      "Time:                        01:39:21   Log-Likelihood:            -3.4129e+05\n",
      "No. Observations:              478467   AIC:                         6.826e+05\n",
      "Df Residuals:                  478465   BIC:                         6.826e+05\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      0.5802      0.001    571.373      0.000       0.578       0.582\n",
      "same_sex      -0.0034      0.001     -2.371      0.018      -0.006      -0.001\n",
      "==============================================================================\n",
      "Omnibus:                  1741221.281   Durbin-Watson:                   1.978\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            79944.712\n",
      "Skew:                          -0.318   Prob(JB):                         0.00\n",
      "Kurtosis:                       1.101   Cond. No.                         2.63\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "===========\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                empstat   R-squared:                       0.000\n",
      "Model:                            OLS   Adj. R-squared:                 -0.000\n",
      "Method:                 Least Squares   F-statistic:                    0.1788\n",
      "Date:                Tue, 07 Nov 2023   Prob (F-statistic):              0.672\n",
      "Time:                        01:39:21   Log-Likelihood:            -1.3262e+05\n",
      "No. Observations:              194410   AIC:                         2.652e+05\n",
      "Df Residuals:                  194408   BIC:                         2.653e+05\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      0.3560      0.002    230.956      0.000       0.353       0.359\n",
      "same_sex      -0.0009      0.002     -0.423      0.672      -0.005       0.003\n",
      "==============================================================================\n",
      "Omnibus:                   914246.783   Durbin-Watson:                   2.008\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            33478.081\n",
      "Skew:                           0.604   Prob(JB):                         0.00\n",
      "Kurtosis:                       1.365   Cond. No.                         2.63\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Regression 2:\n",
    "\n",
    "modelUS = ols(\"empstat ~ same_sex\", dataUS,missing=\"drop\").fit()\n",
    "print(modelUS.summary())\n",
    "thing2_US = modelUS.params[\"same_sex\"]\n",
    "\n",
    "print(\"===========\")\n",
    "\n",
    "modelTk = ols(\"empstat ~ same_sex\", dataTurkey).fit()\n",
    "print(modelTk.summary())\n",
    "thing2_Tk = modelTk.params[\"same_sex\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "US:\n",
      "thing1:\t 0.04706943816732044\n",
      "thing2:\t -0.0033852108139728887\n",
      "thing3:\t -0.07191950755688405\n",
      "Turkey:\n",
      "thing1:\t 0.06706980065470287\n",
      "thing2:\t -0.0009181573768006213\n",
      "thing3:\t -0.013689579629550322\n"
     ]
    }
   ],
   "source": [
    "# Combining them...\n",
    "thing3_US = thing2_US/thing1_US\n",
    "print(\"US:\")\n",
    "print(\"thing1:\\t\", thing1_US)\n",
    "print(\"thing2:\\t\", thing2_US)\n",
    "print(\"thing3:\\t\", thing3_US)\n",
    "\n",
    "thing3_Tk = thing2_Tk/thing1_Tk\n",
    "print(\"Turkey:\")\n",
    "print(\"thing1:\\t\", thing1_Tk)\n",
    "print(\"thing2:\\t\", thing2_Tk)\n",
    "print(\"thing3:\\t\", thing3_Tk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">Interpretation time!</font>\n",
    "\n",
    "<font color=\"red\"> Answer the following questions with a sentence or two each.  (Hint: This is related to HW3...) </font>\n",
    "\n",
    "1. How should we interpret thing1?\n",
    "2. How should we interpret thing2?\n",
    "3. How should we interpret thing3?\n",
    "\n",
    "<font color=\"red\">**TODO:** Double-click the box below and enter your answer. </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANSWER:** \n",
    "1. Speaking in regression terms, it is the coefficient of the independent variable \"same_sex\". In this case, the dependent variable is \"three_or_more\". thing1 can be also interpreted as the effect of having same-sex children as the first two children on the woman's likelihood of having three or more children. (It is the effect of treatment on having at least 3 children.)\n",
    "\n",
    "2. Speaking in regression terms, it is the coefficient of the independent variable \"same_sex\". In this case, the dependent variable is \"empstat\". thing2 can be also interpreted as the effect of having same-sex children as the first two children on the woman's employment status. (It is the effect of treatment on employment rate). \n",
    "\n",
    "3. Dividing thing2 by thing 1 (as we did in HW3), we obtain thing3, which is the value of the ATE among the compliers(LATE). Looking at the values of thing3 for the two populations, we can tell that the eployment rates of TR women with two children were affected less by them having a third child (or more than 3 children) than those of US women. Hence, US women are more prone to unemployment when they have three or more children. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B3:  Are there selection effects?\n",
    "\n",
    "Just like in Part A4, we can look at what observables, if any, seem related to being \"in the treatment group.\"  In this case, being in the treatment group means having first two children of the same sex.\n",
    "\n",
    "Below, we chose a few variables, but feel free to choose different ones and play around with it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:               same_sex   R-squared:                       0.000\n",
      "Model:                            OLS   Adj. R-squared:                 -0.000\n",
      "Method:                 Least Squares   F-statistic:                    0.8927\n",
      "Date:                Tue, 07 Nov 2023   Prob (F-statistic):              0.467\n",
      "Time:                        02:07:50   Log-Likelihood:            -3.4723e+05\n",
      "No. Observations:              478467   AIC:                         6.945e+05\n",
      "Df Residuals:                  478462   BIC:                         6.945e+05\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      0.5066      0.008     62.624      0.000       0.491       0.522\n",
      "age        -5.277e-05      0.000     -0.278      0.781      -0.000       0.000\n",
      "education   4.102e-06      0.000      0.011      0.991      -0.001       0.001\n",
      "married       -0.0015      0.002     -0.911      0.362      -0.005       0.002\n",
      "low_educ       0.0025      0.002      1.057      0.291      -0.002       0.007\n",
      "==============================================================================\n",
      "Omnibus:                  1630011.493   Durbin-Watson:                   0.000\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            79742.126\n",
      "Skew:                          -0.023   Prob(JB):                         0.00\n",
      "Kurtosis:                       1.001   Cond. No.                         374.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:               same_sex   R-squared:                       0.000\n",
      "Model:                            OLS   Adj. R-squared:                  0.000\n",
      "Method:                 Least Squares   F-statistic:                     2.436\n",
      "Date:                Tue, 07 Nov 2023   Prob (F-statistic):             0.0449\n",
      "Time:                        02:07:50   Log-Likelihood:            -1.1399e+05\n",
      "No. Observations:              157069   AIC:                         2.280e+05\n",
      "Df Residuals:                  157064   BIC:                         2.280e+05\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      0.5159      0.018     28.434      0.000       0.480       0.551\n",
      "age            0.0002      0.000      0.787      0.431      -0.000       0.001\n",
      "education      0.0008      0.001      0.796      0.426      -0.001       0.003\n",
      "married       -0.0247      0.011     -2.282      0.023      -0.046      -0.003\n",
      "low_educ      -0.0003      0.007     -0.040      0.968      -0.014       0.013\n",
      "==============================================================================\n",
      "Omnibus:                   535290.230   Durbin-Watson:                   0.000\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            26171.680\n",
      "Skew:                          -0.015   Prob(JB):                         0.00\n",
      "Kurtosis:                       1.000   Cond. No.                         478.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "modelUS = ols(\"same_sex ~ age + education + married + low_educ\", dataUS, missing=\"drop\").fit()\n",
    "print(modelUS.summary())\n",
    "\n",
    "modelTk = ols(\"same_sex ~ age + education + married + low_educ\", dataTurkey, missing=\"drop\").fit()\n",
    "print(modelTk.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">Interpretation time!</font>\n",
    "\n",
    "<font color=\"red\"> What do you think?  Are there \"selection effects\" we should worry about? Are there any observables that predict whether or not a woman will be in the treatment group?  </font>\n",
    "\n",
    "<font color=\"violet\"> **OPTIONAL:** Feel free to play around with different variables in the regression, or investigate leads further! </font>\n",
    "\n",
    "<font color=\"red\">How does your answer make you feel about the validity of our instrumental variable for establishing causal effects?</font>\n",
    "\n",
    "**WARNING:** If you play around with the variables, not that if you run a regression with a covariate like \"spouse_age\", which is missing *unless* the person is married, then Python will drop all of the entries where that covariate is missing.  In particular, in that case Python will drop all of the unmarried women, so if you then try to also throw in the covariate \"married,\" you might get something silly. \n",
    "\n",
    "<font color=\"red\">**TODO:** Double-click the box below and enter your answer. </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANSWER:** All of the P-values of the variables among the US population are well above the standard P-value threshold. This implies that we were not able to capture statistically important relationship from the coefficients. The coefficients themselves also have low magnitudes -- therefore, even if their P-values were very small (there a statistically important relationship captured by the coefficient), their effect on selection would be negligible. \n",
    "\n",
    "Apart from married, the same can be said for the Turkish population. In TR, married has a smaller P-value of 0.023 and greater coefficient magnitude of -0.0247, which can effect sellection among the Turkish population. Note that its effect on selection is also somewhat negligible due to the low magnitude and P-value being greater than the threshold (0.05).  \n",
    "\n",
    "I think the instrumental variable did a excellent job of creating randomized control and treatment group. Using these groups we can accurately estimate the average treatment effect.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OPTIONAL Part B4: Does controlling on other variables in part B2 make a difference?\n",
    "\n",
    "Play around with the regressions from part B2.  Try controlling for other variables as well.  Does that make a difference?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL TODO: Your code for part B4 goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"violet\">OPTIONAL TODO:</font> \n",
    "\n",
    "Double-click this box and interpret your answers for (optional) part B4 here.\n",
    "\n",
    "**ANSWER/Interpretation:** TODO (optional) \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
